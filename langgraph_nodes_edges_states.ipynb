{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2P4ooAaNUEBt",
        "outputId": "c2e5eb59-ad1b-4a47-8904-1b046efd8e51"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_google_genai langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8KYp61YQVU_n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "GEMINI_API_KEY = os.environ['GOOGLE_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-NSUz5xnVWI1"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    temperature=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml77Q5nRWp3H",
        "outputId": "41906f82-8c44-47a0-e935-bf3fac6586e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8c535f76-d775-479b-ae2d-4b8a5ba2ec12-0', usage_metadata={'input_tokens': 1, 'output_tokens': 11, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = llm.invoke(\"Hi\")\n",
        "result # Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rtLYAogjWtio",
        "outputId": "8e2aa978-ab03-4ece-d86a-2304406fe305"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hi there! How can I help you today?'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ruEam3PGW4RK",
        "outputId": "0ba683ba-00a7-42b5-f77c-b9c1c698a63d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hi there! How can I help you today?'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "msg = HumanMessage(content=\"Hi\")\n",
        "\n",
        "messages = [msg]\n",
        "\n",
        "result = llm.invoke(messages)\n",
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "uW96eJpFXn7B",
        "outputId": "0b282b57-2cdf-41cf-f9a8-4fe214c956e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"LangChain is a framework for developing applications powered by large language models (LLMs).  It's designed to make it easier to build these applications by providing a standard structure and reusable components.  Think of it as a toolbox filled with pre-built parts and tools specifically for working with LLMs.\\n\\nHere's a breakdown of its key features and what makes it useful:\\n\\n* **Modular Design:** LangChain breaks down the process of building LLM applications into modular components.  This allows developers to easily swap out different LLMs, prompts, memory mechanisms, and other elements without rewriting large portions of their code.\\n\\n* **Chain Functionality:**  It excels at chaining together different components to create complex workflows. For example, you might chain together a prompt generator, an LLM, and a summarizer to create an application that answers questions from a large document.\\n\\n* **Memory Management:**  LangChain provides tools for managing the context and memory of conversations with LLMs. This is crucial for maintaining coherence in long conversations or interactions that span multiple requests.\\n\\n* **Agent Capabilities:** LangChain supports agents, which are components that can decide which tools to use to answer a user's query.  This allows for more sophisticated applications that can interact with external resources like databases or APIs.\\n\\n* **Index Functionality:** LangChain provides ways to index and query large datasets of documents, making it easier to build applications that can answer questions based on specific information.\\n\\n\\nIn short, LangChain simplifies the development of LLM-powered applications by providing a structured approach, reusable components, and tools for managing complex interactions.  It's particularly useful for building applications that go beyond simple prompt-and-response interactions.\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [\n",
        "    HumanMessage(content=\"Hi\"),\n",
        "    AIMessage(content=\"Hi there! How can I help you today?\"),\n",
        "    HumanMessage(content=\"What is Langchain?\")\n",
        "]\n",
        "\n",
        "result = llm.invoke(messages)\n",
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "d_RDd0dvZN8B",
        "outputId": "1c378b96-c84b-4d34-f35f-14c4476489fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'You can learn about LangChain from several sources:\\n\\n* **Official LangChain Documentation:** This is the best place to start.  The documentation is well-structured and provides comprehensive information on all aspects of the framework, including tutorials and examples.  You can find it at [https://python.langchain.com/en/latest/](https://python.langchain.com/en/latest/).\\n\\n* **LangChain\\'s GitHub Repository:**  The GitHub repository ([https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)) contains the source code, issue tracker, and contributions from the community.  It\\'s a valuable resource for understanding the inner workings of LangChain and contributing to its development.\\n\\n* **Tutorials and Blog Posts:** Many tutorials and blog posts are available online that cover various aspects of LangChain.  Searching for \"LangChain tutorial\" or \"LangChain examples\" on Google or YouTube will yield numerous results.  Look for tutorials that focus on specific use cases that interest you, such as building a chatbot or a question-answering system.\\n\\n* **LangChain Community:**  Engage with the LangChain community on platforms like Discord or their forum (if available).  This is a great way to ask questions, get help with specific problems, and learn from other users\\' experiences.\\n\\n* **Example Projects:**  The best way to learn is by doing.  Start by working through the examples provided in the official documentation.  Then, try building your own small projects to apply what you\\'ve learned.  This could involve creating a simple chatbot, a document question-answering system, or a summarization tool.\\n\\n\\nRemember to start with the official documentation.  It provides a solid foundation and will guide you through the key concepts and functionalities of LangChain.  Then, supplement your learning with tutorials and community interaction to deepen your understanding and explore advanced topics.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [\n",
        "    HumanMessage(content=\"Hi\"),\n",
        "    AIMessage(content=\"Hi there! How can I help you today?\"),\n",
        "    HumanMessage(content=\"What is Langchain?\"),\n",
        "    AIMessage(content=\"LangChain is a framework for developing applications powered by language models.\"),\n",
        "    HumanMessage(content=\"Where can I learn?\")\n",
        "]\n",
        "\n",
        "result = llm.invoke(messages)\n",
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7hytA6DvZ8ib"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "class LearningState(TypedDict):\n",
        "    prompt: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "mac_state : LearningState = LearningState(prompt=\"Hello from Macbook Air M1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'prompt': 'Hello from Macbook Air M1'}\n",
            "Hello from Macbook Air M1\n",
            "Hello from Macbook Air M1. I am built by Apple Inc.\n",
            "<class 'dict'>\n"
          ]
        }
      ],
      "source": [
        "print(mac_state)\n",
        "print(mac_state[\"prompt\"])\n",
        "print(mac_state[\"prompt\"] + \". I am built by Apple Inc.\")\n",
        "print(type(mac_state))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
